{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2\nfrom tqdm import tqdm\nimport keras\nimport keras.backend as K \nfrom keras.models import Model\nfrom keras.layers import Dense, Dropout, Add, Input, BatchNormalization, Activation\nfrom keras.layers import  Conv2D, MaxPooling2D, AveragePooling2D, Flatten\nfrom keras.regularizers import l2\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "collapsed": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": false
      },
      "cell_type": "code",
      "source": "path = '../input/pan-iit/repository/aryankhandal0-PanIIT-cdc793a/training/solution.csv'\ndata = pd.read_csv(path)\ndata.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b1e9c22159723c7817072cc5a91997da6d12cc47"
      },
      "cell_type": "code",
      "source": "train_data = []\nlabels = []\ntrain_path = '../input/pan-iit/repository/aryankhandal0-PanIIT-cdc793a/training/training'\nfor file in tqdm(os.listdir(train_path)):\n    path = os.path.join(train_path, file)\n    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    img = cv2.resize(img, (200, 200))\n    train_data.append(np.array(img))\n    labels.append(data['category'][int(file.split('.')[0])-1])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "09bf9693cc5c755f4be0b4588cb81854fbfcf83c"
      },
      "cell_type": "code",
      "source": "def main_block(x, filters, n, strides, dropout):\n\t# Normal part\n\tx_res = Conv2D(filters, (3,3), strides=strides, padding=\"same\")(x)# , kernel_regularizer=l2(5e-4)\n\tx_res = BatchNormalization()(x_res)\n\tx_res = Activation('relu')(x_res)\n\tx_res = Conv2D(filters, (3,3), padding=\"same\")(x_res)\n\t# Alternative branch\n\tx = Conv2D(filters, (1,1), strides=strides)(x)\n\t# Merge Branches\n\tx = Add()([x_res, x])\n\n\tfor i in range(n-1):\n\t\t# Residual conection\n\t\tx_res = BatchNormalization()(x)\n\t\tx_res = Activation('relu')(x_res)\n\t\tx_res = Conv2D(filters, (3,3), padding=\"same\")(x_res)\n\t\t# Apply dropout if given\n\t\tif dropout: x_res = Dropout(dropout)(x)\n\t\t# Second part\n\t\tx_res = BatchNormalization()(x_res)\n\t\tx_res = Activation('relu')(x_res)\n\t\tx_res = Conv2D(filters, (3,3), padding=\"same\")(x_res)\n\t\t# Merge branches\n\t\tx = Add()([x, x_res])\n\n\t# Inter block part\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\treturn x\n\ndef build_model(input_dims, output_dim, n, k, act= \"relu\", dropout=None):\n\t\"\"\" Builds the model. Params:\n\t\t\t- n: number of layers. WRNs are of the form WRN-N-K\n\t\t\t\t It must satisfy that (N-4)%6 = 0\n\t\t\t- k: Widening factor. WRNs are of the form WRN-N-K\n\t\t\t\t It must satisfy that K%2 = 0\n\t\t\t- input_dims: input dimensions for the model\n\t\t\t- output_dim: output dimensions for the model\n\t\t\t- dropout: dropout rate - default=0 (not recomended >0.3)\n\t\t\t- act: activation function - default=relu. Build your custom\n\t\t\t\t   one with keras.backend (ex: swish, e-swish)\n\t\"\"\"\n\t# Ensure n & k are correct\n\tassert (n-4)%6 == 0\n\tassert k%2 == 0\n\tn = (n-4)//6 \n\t# This returns a tensor input to the model\n\tinputs = Input(shape=(input_dims))\n\n\t# Head of the model\n\tx = Conv2D(16, (3,3), padding=\"same\")(inputs)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\n\t# 3 Blocks (normal-residual)\n\tx = main_block(x, 16*k, n, (1,1), dropout) # 0\n\tx = main_block(x, 32*k, n, (2,2), dropout) # 1\n\tx = main_block(x, 64*k, n, (2,2), dropout) # 2\n\t\t\t\n\t# Final part of the model\n\tx = AveragePooling2D((8,8))(x)\n\tx = Flatten()(x)\n\toutputs = Dense(output_dim, activation=\"softmax\")(x)\n\n\tmodel = Model(inputs=inputs, outputs=outputs)\n\treturn model\n\n\nif __name__ == \"__main__\":\n\tmodel = build_model((100,100,1), 6, 22, 8)\n\tmodel.summary()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0465126294b4f59b942f78800a1fa26ec21df3f1"
      },
      "cell_type": "code",
      "source": "shape, classes = (200, 200, 1), 7\nmodel = build_model(shape, classes, 22, 4)\nmodel.compile(\"adam\", \"categorical_crossentropy\", [\"accuracy\"])\nmodel.fit(X, y, epochs=40)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f161bc361c9b013287808ee62355d2e671b41a43"
      },
      "cell_type": "code",
      "source": "test_data = []\nsno = []\ntest_path = 'PanIIT/testing'\nfor file in tqdm(os.listdir(test_path)):\n    path = os.path.join(test_path, file)\n    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    img = cv2.resize(img, (200, 200))\n    name = int(file.split('.')[0])\n    sno.append(name)\n    test_data.append(np.array(img))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "55933a1f1e60c091b7e4fc31dc941f7d9e9830bb"
      },
      "cell_type": "code",
      "source": "X = test_data\nX = np.array(X).reshape(len(X),200,200,1)\nX = X/255.0",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4ea6c81f58fc36fdd1ae1bca1db1dc757a66bbac"
      },
      "cell_type": "code",
      "source": "label = []\nfor i in tqdm(range(len(X1))):\n    y = model.predict(X1[i:i+1])\n    label.append(np.argmax(y))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f681c1af55579b46e9696c7046cb0a531ee3aa3e"
      },
      "cell_type": "code",
      "source": "data = { 'id': sno, 'category': label}\nsubmission = pd.DataFrame(data)\nsubmission.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e23e631f5a8b6b965a9eb2e640fe9a7e2c15225f"
      },
      "cell_type": "code",
      "source": "submission.to_csv('finalsubmit.csv',index=False)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}